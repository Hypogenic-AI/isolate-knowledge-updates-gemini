\begin{thebibliography}{6}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Hsueh et~al.(2024)Hsueh, Wang, Hsu, Chen, and Lee]{hsueh2024pitfalls}
Cheng-Hsun Hsueh, Yi-Chen Wang, Wei-Hao Hsu, Yu-Ting Chen, and Hung-yi Lee.
\newblock An in-depth exploration of pitfalls of knowledge editing in {LLMs}.
\newblock \emph{arXiv preprint arXiv:2406.01436}, 2024.

\bibitem[Levy et~al.(2017)Levy, Seo, Choi, and Zettlemoyer]{levy2017zero}
Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer.
\newblock Zero-shot relation extraction via reading comprehension.
\newblock In \emph{Proceedings of CoNLL}, 2017.

\bibitem[Meng et~al.(2022)Meng, Bau, Andonian, and Belinkov]{meng2022rome}
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.
\newblock Locating and editing factual associations in {GPT}.
\newblock In \emph{Proceedings of NeurIPS}, 2022.

\bibitem[Meng et~al.(2023)Meng, Sharma, Andonian, Belinkov, and
  Bau]{meng2022memit}
Kevin Meng, Arnab~Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau.
\newblock Mass-editing memory in a transformer.
\newblock In \emph{Proceedings of ICLR}, 2023.

\bibitem[Ni et~al.(2023)]{ni2023forgetting}
Shiwen Ni et~al.
\newblock Forgetting before learning: Utilizing parametric arithmetic for
  knowledge updating.
\newblock \emph{arXiv preprint arXiv:2311.08011}, 2023.

\bibitem[Zhang et~al.(2024)]{zhang2024arithmetic}
Wei Zhang et~al.
\newblock Interpreting and improving large language models in arithmetic
  calculation.
\newblock \emph{arXiv preprint arXiv:2409.01659}, 2024.

\end{thebibliography}
